{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a Jupyter Notebook. It is an interactive document that contains both rich text elements such as figures, links, equations, etc. and executable code - in this case Python code (the grey boxes).\n",
    "**How to use a Jupyter Notebook**: You can execute the blocks of code one at the time by placing the mouse in the grey box and pressing shift + enter. An asterisk will appear in the brackets at the top left of the box while the code is being executed (this may take few seconds) and turns into a number when the execution is over. Alternatively, you can run all the code in the Notebook in a single step by clicking on the menu Cell -> Run All.*\n",
    "\n",
    "# GSA tutorial - What are the most important parameters in a mathematical model?\n",
    "Francesca Pianosi, Fanny Sarrazin, Andres Peñuela\n",
    "\n",
    "Mathematical models often encompass a large number of parameters. The value of these parameters for a particular application are decided by the modeller based on information about the quantities that these parameters represent (for example, measurements from field work or from lab experiments). Alternatively, if the modeller possesses some observations of the system' input and output variables, the parameterss can be estimated by finding the values that makes the model best fit those observations (this process is called *model calibration*). \n",
    "In both cases, determining the 'right' parameter values is often difficult and time consuming, as it may require acquiring and handling a lot of data and/or using of a lot of computing power (if the model is calibrated using a computer algorithm). In this Notebook we see how Global Sensitivity Analysis (GSA) can help in this context, by allowing us to determine the relative importance of the parameters on the model predictions, and therefore identify the most influential parameters on which estimation efforts should be focused on.\n",
    "\n",
    "# A hydrological example\n",
    "\n",
    "In this Notebook we will apply GSA to determine the influential and uninfluential parameters of a hydrological model. A hydrological model takes time series of meteorological forcings (rainfall and temperature) over a river basin, and returns the time series of river flows at the basin outlet. For the sake of illustration, here we will use a very simple model, the Hymod model (Boyle 2001; Wagener et al. 2001), which only has five parameters. These parameters represent some key basin characteristics that determine the transformation of rainfall into flow, such as the soil's water holding capacity and the velocity with which water travels in the sub-surface. \n",
    "We will apply the model to the Leaf catchment in the USA (Sorooshian et al., 1983), for which we possess daily observations of rainfall (R), potential evaporation (PE) and river flow (Q), which can be used for the model calibration. Specifically, we will measure the model's fit-to-data with two performance metrics: the Root Mean Squared Error (RMSE) and the volumetric bias (BIAS). We will show how GSA can be used to quantify the relative importance of the five model parameters in controlling these performance metrics. \n",
    "\n",
    "<left><img src=\"hyd/Hymod_fig.png\" width=\"700px\">\n",
    "   \n",
    "### Programme\n",
    "1. Model setup. Load the data and get familiar with the Hymod rainfall-runoff model through a One-At-the-Time Sensitivity Analysis\n",
    "2. Monte Carlo simulation (forward propagation of uncertainty): sample the model parameter within their ranges and run the model to obtain an ensemble of river flow predictions. \n",
    "3. Global Sensitivity Analysis using the PAWN method (backward attribution of uncertainty): use PAWN (Pianosi and Wagener, 2018) to formally assess the effect of parameter variations on the output metrics (RMSE and BIAS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Model setup and One-At-the-Time Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to hide warning messages\n",
    "\n",
    "# Install python package for interactive visualisation and import required functions:\n",
    "%pip install -q ipywidgets\n",
    "from ipywidgets import interact, FloatRangeSlider, IntRangeSlider\n",
    "\n",
    "# Install SAFE package and import required functions\n",
    "%pip install SAFEpython\n",
    "import safepython.PAWN as PAWN # Module to calculate PAWN sensitivity indices\n",
    "import safepython.plot_functions as pf # Module to visualize the results\n",
    "from safepython.model_execution import model_execution # Module to execute the model\n",
    "from safepython.sampling import AAT_sampling, AAT_sampling_extend # Functions to perform the input sampling\n",
    "from safepython.util import aggregate_boot # Functions to perform bootstrapping\n",
    "from safepython.util import RMSE\n",
    "# Module that simulates the HyMod model:\n",
    "from safepython import HyMod\n",
    "# Import the additional function BIAS in the BIAS.py module\n",
    "from hyd_bias import BIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (one year of daily observations of rainfall, potential evaporation and flow):\n",
    "data = np.genfromtxt('hyd/LeafCatch.txt', comments='%')\n",
    "rain = data[0:365, 0] # select the first year of data\n",
    "evap = data[0:365, 1]\n",
    "flow = data[0:365, 2]\n",
    "warmup = 30 # Model warmup period (days)\n",
    "\n",
    "# Plot data:\n",
    "plt.figure(figsize=[15,7])\n",
    "plt.subplot(311); plt.plot(rain); plt.ylabel('rainfall (mm/day)')\n",
    "plt.subplot(312); plt.plot(evap); plt.ylabel('evaporation (mm/day)')\n",
    "plt.subplot(313); plt.plot(flow, color=[0.7, 0.7, 0.7]); plt.ylabel('flow (mm/day)')\n",
    "plt.xlabel('time (days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-At-the-Time Sensitivity Analysis\n",
    "We are now ready to run the Hymod model. To do this, we will set the five model parameters to some tentative values, run the model and plot the resulting streamflow time series. We can then change the parameter values one-at-a-time and look at how this changes the model predictions, and their fit to observed flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define interactive visualisation function to set the parameters to some tentative values, \n",
    "# run the model and plot the resulting streamflow time series\n",
    "\n",
    "def oat_function(Sm = 200, beta = 0.5, alpha = 0.7, Rs = 0.05, Rf = 0.6):\n",
    "    # Set a tentative parameterization:\n",
    "    param = np.array([Sm, beta, alpha, Rs, Rf]) # Sm (mm), beta (-), alfa (-), Rs (-), Rf (-)\n",
    "    # Run simulation:\n",
    "    flow_sim, _, _ = HyMod.hymod_sim(param, rain, evap)\n",
    "    # Plot results:\n",
    "    plt.figure(figsize=[15,3])\n",
    "    plt.plot(flow, color=[0.7, 0.7, 0.7]) # observed flow\n",
    "    plt.plot(flow_sim, 'k') # simulated flow\n",
    "    plt.ylabel('flow (mm/day)')\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.legend(['obs', 'sim'])\n",
    "    plt.title(\"RMSE = %g\" % RMSE(flow_sim[warmup:365],flow[warmup:365]) + \" (mm/day) - BIAS = %g\" % BIAS(flow_sim[warmup:365],flow[warmup:365]) + \" (mm/day)\" )\n",
    "    plt.show()\n",
    "    \n",
    "interact(oat_function, Sm = (0, 400, 1), beta = (0, 2, 0.1), alpha = (0,1,0.1), Rs = (0,0.1,0.01), Rf = (0.1,1,0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* What is the effect of varying each model parameter? [*Hydrology question: which parameter controls which characteristic (timing, peak, recession phase, etc.) of the simulated flow time series?*]\n",
    "* Can you tell which parameters mostly control the model predictions and fit-to-observations?\n",
    "* What are the pros and cons of OAT sensitivity analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 - Monte Carlo simulations and qualitative (visual) Global Sensitivity Analysis\n",
    "\n",
    "In this section, we run Monte Carlo (MC) simulations of the model against a prescribed number of parameter combinations, randomly drawn from the feasible parameter ranges. Each model simulation provides a times series of streamflow predictions. For each time series, we will measure the distance from observations by means of a synthetic performance metric. Here we have implemented two possible metrics: the Root Mean Squared Error (RMSE) and the volumetric Bias (BIAS). The global sensitivity analysis can thus be repeated twice, once for RMSE and once for the BIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variability space:\n",
    "X_Labels = ['Sm', 'beta', 'alfa', 'Rs', 'Rf'] # Name of parameters (used to customize plots)\n",
    "M = len(X_Labels) # Number of parameters\n",
    "distr_fun = st.uniform # Parameter distributions\n",
    "xmin = [0, 0, 0, 0, 0.1] # Parameter ranges (lower bound)\n",
    "xmax = [400, 2, 1, 0.1, 1] # Parameter ranges (upper bound)\n",
    "\n",
    "# Save lower and upper bound in the appropriate format to be passed on to the sampling function:\n",
    "distr_par = [np.nan] * M\n",
    "for i in range(M):\n",
    "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
    "\n",
    "# Choose sampling strategy and size:\n",
    "samp_strat = 'lhs' # sampling strategy\n",
    "# options:\n",
    "# 'lhs' = Latin Hypercube sampling\n",
    "# 'rsu' = Random uniform sampling\n",
    "\n",
    "# Choose the number of samples:\n",
    "N = 500 \n",
    "\n",
    "# Perform sampling:\n",
    "X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n",
    "\n",
    "# Execute the model against all the input samples in 'X':\n",
    "QQ = model_execution(HyMod.hymod_sim, X, rain, evap)\n",
    "\n",
    "# Plot Monte Carlo (MC) simulations results and compare with data:\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.plot(flow, color=[0.7, 0.7, 0.7]) # plot for legend\n",
    "plt.plot(np.transpose(QQ), 'k', linewidth = 0.5)\n",
    "plt.plot(flow, color=[0.7, 0.7, 0.7])\n",
    "plt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\n",
    "plt.legend(['obs', 'sim'])\n",
    "plt.title(\"Number of parameter samples: N = %d\" % N, loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aggregate time series into scalar output metric(s) and produce scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE and BIAS for each parameter sample:\n",
    "YY = np.nan * np.ones((N, 2))\n",
    "YY[:, 0] = RMSE(QQ[:, warmup:365], flow[warmup:365])\n",
    "YY[:, 1] = BIAS(QQ[:, warmup:365], flow[warmup:365])\n",
    "\n",
    "# Define interactive visualisation function to produce scatter plots for the chosen output metrics:\n",
    "def scatter_function(metric='RMSE'):\n",
    "    if metric == 'RMSE':\n",
    "        i = 0\n",
    "    elif metric == 'BIAS':\n",
    "        i = 1\n",
    "            \n",
    "    # Extract output metric:\n",
    "    Y = YY[:, i]; \n",
    "    Y_Label = metric + '(mm/day)'\n",
    "\n",
    "    # Scatter plots of the output metric against input samples:\n",
    "    plt.figure(figsize=[15,3])\n",
    "    pf.scatter_plots(X, Y, Y_Label=Y_Label, X_Labels=X_Labels)\n",
    "    plt.title(\"Number of parameter samples: N = %d\" % N, loc='right')\n",
    "    plt.show()\n",
    "    \n",
    "interact(scatter_function, metric = ['RMSE','BIAS']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "* From these scatter plots, which parameter would you say is most influential? Why?\n",
    "* How does the answer changes with the chosen performance metric? [*Hydrology question: can you interpret why certain parameters are more important for RMSE and others for BIAS?*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Global Sensitivity Analysis using the PAWN method\n",
    "In this section, we formally assess the sensitivity of the performance metrics to the model parameters through the PAWN method (Pianosi and Wagener, 2018). Again, the analysis can be repeated twice, once for the RMSE and once for the BIAS. For each performance metric, we can also assess the impact of the choice of the tuning parameters of the PAWN method: the number of conditioning interval (n), the aggregation statistic (median, mean, max) and the number of bootstrap resamples (Nboot) used to estimate confidence intervals of the PAWN indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define interactive visualisation function to calculate and visualise sensitivity indices\n",
    "# for the chosen output metric and different choices of the PAWN tuning parameters (n,Nboot,aggr)\n",
    "\n",
    "def pawn_function(metric='RMSE', n = 5, aggr = 'median',Nboot = 500):\n",
    "    # Extract output metric:\n",
    "    if metric == 'RMSE':\n",
    "        i = 0\n",
    "    elif metric == 'BIAS':\n",
    "        i = 1   \n",
    "    Y = YY[:, i]; \n",
    "    \n",
    "    # Apply PAWN\n",
    "    # Tuning parameters:\n",
    "    # n = number of conditioning intervals\n",
    "    # aggr = statistic to aggregate KS values\n",
    "    # Nboot = number of bootstrapping resamples used to derive confidence bounds of sensitivity indices   \n",
    "\n",
    "    # Compute sensitivity indices for Nboot bootstrap resamples\n",
    "    KS_median, KS_mean, KS_max = PAWN.pawn_indices(X, Y, n, Nboot=Nboot)\n",
    "    # KS_median and KS_mean and KS_max have shape (Nboot, M)\n",
    "        \n",
    "    # Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:\n",
    "    KS_median_m, KS_median_lb, KS_median_ub = aggregate_boot(KS_median) # shape (M,)\n",
    "    KS_mean_m, KS_mean_lb, KS_mean_ub = aggregate_boot(KS_mean) # shape (M,)\n",
    "    KS_max_m, KS_max_lb, KS_max_ub = aggregate_boot(KS_max) # shape (M,)\n",
    "\n",
    "    # Plot sensitivity indices:\n",
    "    plt.figure()\n",
    "    plt.title(\"Output metric = %s\" % metric)\n",
    "    if aggr == 'median':\n",
    "        pf.boxplot1(KS_median_m, S_lb=KS_median_lb, S_ub=KS_median_ub, X_Labels=X_Labels, Y_Label='sensitivity (median KS)')\n",
    "    if aggr == 'mean':\n",
    "        pf.boxplot1(KS_mean_m, S_lb=KS_mean_lb, S_ub=KS_mean_ub, X_Labels=X_Labels, Y_Label='sensitivity (mean KS)')\n",
    "    if aggr == 'max':\n",
    "        pf.boxplot1(KS_max_m, S_lb=KS_max_lb, S_ub=KS_max_ub, X_Labels=X_Labels, Y_Label='sensitivity (max KS)')\n",
    "    plt.show()\n",
    "    \n",
    "interact(pawn_function, metric = ['RMSE','BIAS'], n = (2, 20, 1), aggr = ['median', 'mean','max'], Nboot = (0, 500, 10));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "* Which parameter are most influential on each performance metric? Are these results consistent with the visual inspection of the scatter plots?\n",
    "* *Advanced GSA question: What is the impact of changing n and Nboot? Why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Boyle, D. (2001). Multicriteria calibration of hydrological models. PhD thesis, Dep. of Hydrol. and Water Resour., Univ. of Ariz., Tucson.\n",
    "\n",
    "Pianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis’. Env. Mod. & Soft., 70, 80-85.\n",
    "\n",
    "Pianosi and Wagener (2018). Distribution-based sensitivity analysis from a generic input-output sample, Env. Mod. & Soft., 108, 197-207.\n",
    "\n",
    "Wagener, T., Boyle, D., Lees, M., Wheater, H., Gupta, H., and Sorooshian, S. (2001). A framework for development and application of hydrological models. Hydrol. Earth Syst. Sci., 5, 13-26.\n",
    "\n",
    "Sorooshian at al. (1983). Evaluation of maximum likelihood parameter estimation techniques for conceptual rainfall-runoff models: Influence of calibration data variability and length on model credibility. Water Resour. Res., 19, 251–259."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

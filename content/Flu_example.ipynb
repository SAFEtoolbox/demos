{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a Jupyter Notebook. It is an interactive document that contains both rich text elements such as figures, links, equations, etc. and executable code - in this case Python code (the grey boxes).\n",
    "**How to use a Jupyter Notebook**: You can execute the blocks of code one at the time by placing the mouse in the grey box and pressing shift + enter. An asterisk will appear in the brackets at the top left of the box while the code is being executed (this may take few seconds) and turns into a number when the execution is over. Alternatively, you can run all the code in the Notebook in a single step by clicking on the menu Cell -> Run All.*\n",
    "\n",
    "# GSA tutorial - Using GSA to enhance model-informed decisions under uncertainty\n",
    "Francesca Pianosi, Fanny Sarrazin, Andres Penuela-Fernandez\n",
    "\n",
    "Mathematical models are often used to inform decision-makers dealing with complex management problems. The model is used to predict the consequences of alternative actions, hence providing a quantitative assessment of their benefits and costs, possibly under different uncertain scenarios. In this context, Global Sensitivity Analysis (GSA) can be used to investigate the space of possible actions in a more comprehensive and structured way, including a range of actions possibly larger than the few ones that decision-makers would test in a traditional 'what-if?' analysis. GSA can also help quantifying the importance of these actions relative to other factors that influence the system response, but that are not controllable and potentially highly uncertain (Ref. 1).\n",
    "\n",
    "\n",
    "# An epidemiological example\n",
    "\n",
    "In this Notebook we will use a simple epidemiological model, which provides a mathematical description of the spread of an infectious deasease, such as flu, within a population. \n",
    "\n",
    "The **model** divides the population into three \"compartments\":\n",
    "* Vulnerable: individuals who are vulnerable but not yet infected with the flu\n",
    "* Sick: individuals who are infected with the flu\n",
    "* Immune: individuals who have immunity to the flu. This includes individuals who either have recovered from the flu or have been vaccinated.\n",
    "\n",
    "The model describes the change in the number of individuals in each compartment over time, using five parameters:\n",
    "* <font color='blue'>Initial number of vaccinated individuals</font>: people who are immune at the start of the flu season because they were previously vaccinated.\n",
    "* <font color='blue'>Recovery time</font>: the average number of days to get fully recovered\n",
    "* <font color='green'>Contact rate per day</font>: number of times that an infected individual comes into contact with a vulnerable individual in a day\n",
    "* <font color='green'>Contagion ratio</font>: proportion of contacts that result in infection\n",
    "* <font color='green'>Vaccination rate</font>: number of inviduals who are vaccinated per day during the outbreak\n",
    "\n",
    "Let's consider the following **decision-making problem**. In a city with a population of 100,000 people, we would like to simulate and compare three possible actions to be taken during the flu season:\n",
    "* Implementing social distancing measures to reduce the <font color='green'>daily contact rate</font>. A reduction of 0.1 points of this rate is estimated to cost £20,000.\n",
    "* Distributing face masks to reduce the <font color='green'>contagion rate</font>. Reducing this rate by 0.1 points is estimated to cost £5,000.\n",
    "* Increasing the <font color='green'>vaccination rate</font> during the flu season. The vaccination cost is of £7 per person.\n",
    "\n",
    "The objective is to keep the sick population below 25% (25,000 people) at any time, because above this number the healthcare system is overwhelmed; and to do so within the total available budget, which is £300,000. However, the effects of our decisions also depend on <font color='blue'>initial number of vaccinated individuals</font> at the start of the flu season, and the <font color='blue'>recovery time</font>. Both these factors are not known exactly, and it can only be estimated that the number of people initially vaccinated should range between 0 and 50,000 (half of the population), and the recovery time should vary between 7 and 14 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - One-At-the-Time 'what-if?' analysis\n",
    "In this section, we will run the epidemiological model by changing its parameters one at the time. The goal is to determine a combination of decion-related parameters (contagion ratio, recovery time, vaccination rate) that lead to the desired outputs (that is, to maintain the sick population at peak and the total cost under their respective targets), and that do so under as many combinations as possible of the other two uncertain parameters (initial vaccinated population and recovery time) that are not under our control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to hide warning messages\n",
    "\n",
    "# Install python package for interactive visualisation and import required functions:\n",
    "%pip install -q ipywidgets\n",
    "from ipywidgets import interact, FloatRangeSlider, IntRangeSlider\n",
    "\n",
    "# Install SAFE package and import required functions\n",
    "%pip install SAFEpython\n",
    "import safepython.RSA_thres as RSA_tr # Module that implements RSA\n",
    "import safepython.plot_functions as pf # Module to visualize the results\n",
    "from safepython.model_execution import model_execution # Module to execute the model\n",
    "from safepython.sampling import AAT_sampling, AAT_sampling_extend # Functions to perform the input sampling\n",
    "from safepython.util import aggregate_boot # Functions to perform bootstrapping\n",
    "from safepython.util import empiricalcdf\n",
    "# Module that simulates the epidemiological model:\n",
    "import flu_fun as flu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model\n",
    "We are now ready to run the model. Execute the block of code below, and then use the slider to change the parameter values. Can you determine a combination of decion-related parameters (*contagion ratio*, *recovery time*, *vaccination rate*) that maintain number of sick individuals at peak below **25,000** at all times, for a total cost of less than **£300,000** - under as as many combinations as possible of *initial vaccinated population* and *recovery time*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nday = 100 # days\n",
    "Npop = 100000 # individuals in the total population\n",
    "target1 =  25000 # target for max number of sick individuals\n",
    "target2 = 350000 # target for max cost (£)\n",
    "t = np.linspace(1,Nday,Nday)\n",
    "def oat_function(contag_ratio = 2, recovery_day = 14, vax_rate=2500,pop_vax_ini = 0, contact_rate = 2):\n",
    "    # Set a tentative parameterization:\n",
    "    param = np.array([pop_vax_ini, contact_rate, contag_ratio, recovery_day, vax_rate])    \n",
    "    # Run simulation:\n",
    "    \n",
    "    S, RI, V,max_value,total_cost = flu.model(param,t,Npop)\n",
    " \n",
    "    # Plot results:\n",
    "    plt.figure(figsize=[12,3])\n",
    "    plt.stackplot(t,S,V,RI,labels=['Sick','Vulnerable','Immune'])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.plot(target1*np.ones((Nday,1)),'r' )\n",
    "    plt.ylabel('population')\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.title(\"No. of sick individuals at peak = %d\" % (max_value) + \" (target: %d\" % (target1) + \")      Total cost (£) = %d\" % (total_cost) + \" (target: %d\" % (target2) + \")\")\n",
    "    plt.xlim((1,Nday))\n",
    "    plt.show()\n",
    "    \n",
    "interact(oat_function, contag_ratio = (0.3, 1, 0.01), recovery_day = (7, 14, 1), vax_rate = (0,5000,10), pop_vax_ini = (0,50000,10), contact_rate = (0.3, 2, 0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Finding robust actions by GSA\n",
    "We can see that it is difficult to find a combination of actions that robustly achieve both targets by varying the parameter values one at the time. In order to facilitate this search, we can use Global Sensitivity Analysis (GSA) to answer questions like:\n",
    "- is it possible at all to find a set of actions (i.e. decision-related parameters) that satisfy both targets against many uncertain scenarios?\n",
    "- which of these decision-related parameters are key to achieve the desired outputs? \n",
    "- which uncertainties are most influential and should be prioritised for uncertainty reduction?\n",
    "- if we could reduce these important uncertainties, what would emerge as best combination of actions to undertake?\n",
    "\n",
    "In GSA, we first generate a number of parameter combinations by randomly sampling from the feasible parameter ranges. Then, we run the model against each of these combinations (this is called Monte Carlo simulations). The results of each model run is associated with our two output metrics of interest: the number of sick individuals at the outbreak peak, and the total vaccination cost. Then, we analyse this sample of parameter combinations and associated output metrics through a mix of qualitative (visual analysis) and quantitative (sensitivity indices) approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variability space:\n",
    "X_Labels = ['pop_vax_ini', 'contact_rate', 'contag_ratio', 'recovery_day', 'vax_rate'] # Name of parameters (used to customize plots)\n",
    "M = len(X_Labels) # Number of parameters\n",
    "distr_fun = st.uniform # Parameter distributions\n",
    "xmin = [ 0   , 0.3, 0.3,  7,    0] # Parameter ranges (lower bound)\n",
    "xmax = [50000, 2.0, 1.0, 14, 5000] # Parameter ranges (upper bound)\n",
    "# Save lower and upper bound in the appropriate format to be passed on to the sampling function:\n",
    "distr_par = [np.nan] * M\n",
    "for i in range(M):\n",
    "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
    "# Choose sampling strategy and size:\n",
    "samp_strat = 'lhs' # sampling strategy (options: 'lhs' = Latin Hypercube sampling,'rsu' = Random uniform sampling)\n",
    "# Choose the number of samples:\n",
    "N = 2000 \n",
    "# Perform sampling:\n",
    "X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n",
    "# Execute the model against all the samples in 'X':\n",
    "Y1 = model_execution(flu.function, X,t,Npop,0) # max number of sick individuals in a day\n",
    "Y2 = model_execution(flu.function, X,t,Npop,1) # total cost of the measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing Monte Carlo samples to quantify output uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency distribution of outputs:\n",
    "Y_Labels = ['sicks at peak','total cost']\n",
    "\n",
    "plt.figure(figsize=[13,4])\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Distribution of output samples', loc='left')\n",
    "plt.hist(Y1, bins=20, color='grey');\n",
    "plt.axvline(x=target1, color='r')\n",
    "plt.ylim((0,N))        \n",
    "plt.ylabel('number of samples')\n",
    "plt.xlabel(Y_Labels[0])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(Y2, bins=20, color='grey');\n",
    "plt.axvline(x=target2, color='r')\n",
    "plt.ylim((0,N))\n",
    "plt.xlabel(Y_Labels[1])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Output 1 vs 2', loc='left')\n",
    "plt.plot(Y1,Y2/10000, '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "plt.xlabel(Y_Labels[0])\n",
    "plt.ylabel(Y_Labels[1]+ \"(x £10,000) \")\n",
    "plt.axvline(x=target1, color='r')\n",
    "plt.axhline(y=target2/10000, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments** For the number of sick individuals at outbreak peak (left), most of the density is to the left of the target (red vertical line), so there are high chances that the target for this output can be achieved. In other words, there are many combinations of parameters that would reach the target against the many different uncertain scenarios. The opposite is true for the total containment cost (middle): the combinations of parameters leading to a total cost less than the target are relatively few, compared to the number of samples that exceed it. \n",
    "<br>\n",
    "From the right plot, we see that several combinations exist where both outputs stay below the set targets (bottom left square). This figure also show the tradeoff between the two outputs, whereby a lower number of sick individuals at peak is generally reached at higher cost. Because of the uncertainty in initial population and recovery time though, the relationship between the two outputs is not univocal, and the same investment (total cost) can lead to different number of sick individuals.\n",
    "<br>\n",
    "In general we find that **the answer to the first question** - is it possible to find combinations of decision-relevant parameters that achieve both targets? - is yes, such combinations exist, but given uncertanties, the total cost target has less chances to be met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Sensitivity indices\n",
    "Now, we use the input-output samples generated in the previous step to calculate sensitivity indices. We usa a GSA method called *Regional Sensitivity Analysis*, or *Monte Carlo filtering* (more insights about how the methods works to calculate sensitivity indices are given in the last section of this Notebook). We calculate three sets of indices, each measuring the relative importance of the 5 input parameters towards:\n",
    "- achieving the target for the number of sick individuals at peak (output 1)\n",
    "- achieving the target for the total costs (output 2)\n",
    "- achieving both targets simoultaneously (output 1&2 jointly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nboot = 50 # Number of resamples used for bootstrapping\n",
    "   \n",
    "plt.figure(figsize=[12,3])\n",
    "mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y1, target1, Nboot=Nboot)\n",
    "mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "pf.boxplot1(mvd_m, S_lb=mvd_lb, S_ub=mvd_ub,Y_Label='Sensitivity',X_Labels=['','','','',''])\n",
    "plt.title(\"Output y1 = \" + Y_Labels[0], loc='center')\n",
    "plt.show()\n",
    "\n",
    "mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y2, target2, Nboot=Nboot)\n",
    "mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "plt.figure(figsize=[12,3])\n",
    "pf.boxplot1(mvd_m, S_lb=mvd_lb, S_ub=mvd_ub,Y_Label='Sensitivity',X_Labels=['','','','',''])\n",
    "plt.title(\"Output y2 = \" + Y_Labels[1], loc='center')\n",
    "plt.show()\n",
    "\n",
    "Y = np.concatenate((Y1,Y2),axis=1)\n",
    "target = [target1,target2]\n",
    "mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y, target, Nboot=Nboot)\n",
    "mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "plt.figure(figsize=[12,3])\n",
    "pf.boxplot1(mvd_m, S_lb=mvd_lb, S_ub=mvd_ub,Y_Label='Sensitivity',X_Labels=X_Labels)\n",
    "plt.title(\"Outputs y1&y2 jointly\", loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments** In the top plot we see that the three most important factors to keep the number of sick individuals at peak below target are: the vaccination rate (5th parameter), the initial vaccinated population (1st), and the contact rate (2nd). The relative importance of the factors changes with the second output, in fact, from the middle plot we see that the total cost is mostly controlled by the vaccination rate, whereas all other factors have substantially less importance. Last, in the bottom plot we look at the importance of factors in keeping both outputs below their targets. In **response to the second question** set out above - <font color='green'>which of the decision-related parameters are key to achieve the desired outputs?</font> - we can conclude that getting the <font color='green'>vaccination rate</font> right is the most important decision. <br>\n",
    "Another interesting observation is that the number of days for recovery (4th parameter) has lower importance than the initial vaccinated population (1st) consistenly across all three output definitions. Hence, **in response to the third question** - <font color='blue'>which uncertainties are most influential and should be prioritised for uncertainty reduction?</font> - we conclude that, if we can invest towards collecting more information and reducing uncertainties, it is best to focus our efforts on reducing the uncertainty about the <font color='blue'>inital number of vaccinated individuals</font>, as this parameter is much more influential. Being able to better estimate the recovery days, instead, is not really important in this context, as this parameter does not have much effect towards reaching our targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing input samples to identify 'robust' decisions\n",
    "\n",
    "Last, we can determine the most robust combinations of actions to undertake - i.e. actions that will result in reaching the set targets across the largest possible range of uncertainties. \n",
    "\n",
    "Once again, the actions are linked to the three decision-relevant parameters: <font color='green'>vaccination rate</font>, <font color='green'>contact rate</font>, and <font color='green'>contagion ratio</font> (in order of importance, as established in previous step). We will use coloured scatter plots to investigate the interactions between these parameters and find combinations that reach the target (both output below their threshold) regardless of the value of the uncertain parameters. \n",
    "\n",
    "We can also analyse how these robust actions change with changing level of uncertainty - for instance as we reduce the uncertainty range around the <font color='blue'>initial number of vaccinated individuals</font>. We will not look at the uncertainty in recovery days because, as we established in previous section, it has very little influence on reaching targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vax_ini_function(vax_ini_min = 0, vax_ini_max = 40000):\n",
    "\n",
    "    vax_ini_idx = ( X[:,0]> vax_ini_min ) & ( X[:,0]< vax_ini_max )\n",
    "    Xr = np.zeros((sum(vax_ini_idx),M))\n",
    "    for i in range(5):\n",
    "        Xr[:,i]=X[vax_ini_idx,i]\n",
    "    Y1r = Y1[vax_ini_idx]\n",
    "    Y2r = Y2[vax_ini_idx]\n",
    "  \n",
    "    Yr = np.concatenate((Y1r,Y2r),axis=1)\n",
    "    target = [target1,target2]\n",
    "    mvd, _, _, idx = RSA_tr.RSA_indices_thres(Xr, Yr, target)\n",
    "\n",
    "    plt.figure(figsize=[15,4])\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(Xr[:, 4], Xr[:, 1]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,4], Xr[idx, 1], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[4])\n",
    "    plt.ylabel(X_Labels[1])\n",
    "    plt.title(\"Combinations of actions (red) that will keep both outputs below target for given range of vax_ini\", loc='left')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(Xr[:, 4], Xr[:, 2]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,4], Xr[idx, 2], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[4])\n",
    "    plt.ylabel(X_Labels[2])\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(Xr[:, 1], Xr[:, 2]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,1], Xr[idx, 2], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[1])\n",
    "    plt.ylabel(X_Labels[2])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(vax_ini_function, vax_ini_min = (0,40000,1000), vax_ini_max = (0,40000,1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments** The first plot on the left shows tht there is a strong interaction between contact rate and vaccination rate, hence it is important to coordinate actions relevant to these parameters in order to ensure reaching the targets. We also observe that if we can reduce the uncertainty in the initial number of vaccinated individuals, the spread of the combinations of actions that may achieve the target is reduced, and the relationship between vaccination rate and contact rate becomes clearer and clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced steps: investigating how Regional Sensitivity Analysis works\n",
    "This last section is for those who want to dig deeper in how sensitivity indices are derived when using Regional Sensitivity Analysis (for more background on this method, see Spear and Hornberger 1980 or Pianosi et al. 2016) and the impact of varying the target threshold on sensitivity results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsa_function(peak_target = target1, cost_target = target2):\n",
    "    # Use the function RSA_indices_thres to split into behavioural (Y<threshold)\n",
    "    # and non-behavioural (Y>threshold) sample:\n",
    "    Y = np.concatenate((Y1,Y2),axis=1)\n",
    "    threshold = [peak_target,cost_target]\n",
    "    Nboot = 50 # Number of resamples used for bootstrapping\n",
    "    mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y, threshold, Nboot=Nboot)\n",
    "    mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "\n",
    "    plt.figure(figsize=[15,8])\n",
    "    # Scatter plots of Output 1 versus each input parameter\n",
    "    for i in range(M):\n",
    "        plt.subplot(3,M,i+1)\n",
    "        plt.plot(X[:, i], Y1/1000  , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "        plt.plot(X[idx,i], Y1[idx, :]/1000, '.', markerfacecolor='r', markeredgecolor='r')\n",
    "        if i==0:\n",
    "            plt.ylabel(Y_Labels[0] + \" (x1000)\")\n",
    "    # Scatter plots of Output 2 versus each input parameter\n",
    "    for i in range(M):\n",
    "        plt.subplot(3,M,M+i+1)\n",
    "        plt.plot(X[:, i], Y2/1000  , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "        plt.plot(X[idx,i], Y2[idx, :]/1000, '.', markerfacecolor='r', markeredgecolor='r')\n",
    "        if i==0:\n",
    "            plt.ylabel(Y_Labels[1] + \" (£x1000)\")\n",
    "    # Empirical distribution of each parameter in the behavioural and non-behavioural set        \n",
    "    for i in range(M):\n",
    "        # Approximate behavioural and non-behavioural distributions:\n",
    "        Xb = X[idx, :]\n",
    "        Xnb = X[~idx, :]\n",
    "        xx = np.unique(sorted(X[:, i]))\n",
    "        CDFb  = empiricalcdf(Xb[:, i], xx)\n",
    "        CDFnb = empiricalcdf(Xnb[:, i], xx)\n",
    "        # Plot CDFs:\n",
    "        plt.subplot(3,M,M+M+i+1)\n",
    "        plt.plot(xx, CDFb , color='r')\n",
    "        plt.plot(xx, CDFnb, color='0.8')\n",
    "        plt.xlabel(X_Labels[i])\n",
    "        if i==0:\n",
    "            plt.ylabel(\"distribution\")\n",
    "            plt.legend(['on target','off target'])\n",
    "    plt.show()\n",
    "\n",
    "    # The sensitivity indices with their 95% confidence intervals:\n",
    "    plt.figure(figsize=[12,3])\n",
    "    pf.boxplot1(mvd_m, S_lb=mvd_lb, S_ub=mvd_ub, X_Labels=X_Labels,Y_Label='Sensitivity')\n",
    "    # plt.title(\"KS with 95%% CI, N = %d\" % N + \", \" + Y_Label + \" = %2.2f\" % threshold)\n",
    "    plt.show()\n",
    "interact(rsa_function, peak_target = (target1-20000,target1+20000,100), cost_target = (250000, 400000, 100));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Pianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis’. Env. Mod. & Soft., 70, 80-85.\n",
    "\n",
    "Pianosi et al. (2016). Sensitivity analysis of environmental models: A systematic review with practical workflow, Env. Mod. & Soft.e, 79, 214-232.\n",
    "\n",
    "Spear and Hornberger (1980). Eutrophication in peel inlet. II. Identification of critical uncertainties via generalized sensitivity analysis, Water Res., 14, 43-49.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
